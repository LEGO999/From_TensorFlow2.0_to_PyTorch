{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7413, 0.3485, 0.6980],\n",
      "        [0.5960, 0.9047, 0.4491],\n",
      "        [0.8232, 0.4518, 0.2927],\n",
      "        [0.4480, 0.3712, 0.0387],\n",
      "        [0.1377, 0.8414, 0.3841]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 所谓的rand 就是从uniform distrubution中创建tensor\n",
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.4556e-18, 1.9421e+31, 2.7491e+20],\n",
      "        [6.1949e-04, 7.1856e+22, 4.3605e+27],\n",
      "        [2.3329e-18, 1.9284e+31, 3.2314e-18],\n",
      "        [3.2675e+21, 8.4569e+20, 6.5644e-07],\n",
      "        [6.7200e-07, 2.6081e+20, 1.6892e-07]])\n"
     ]
    }
   ],
   "source": [
    "# empty 就会返回 当前内存的值， tf与pytorch的不同点在于tf形状一般要用框框起来，而torch都是直接接受未定长度的字符\n",
    "x = torch.empty(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3317, 0.7661, 0.3896],\n",
      "        [0.2991, 0.1369, 0.1923],\n",
      "        [0.9069, 0.5091, 0.0201],\n",
      "        [0.7781, 0.2861, 0.3043],\n",
      "        [0.8398, 0.2941, 0.3473]])\n"
     ]
    }
   ],
   "source": [
    "# rand 会返回零到一之间的数值\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_* methods creates a Tensor with similar type but different size as another Tensor\n",
    "x = x.new_ones(5,3,dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3269, -0.6179, -1.6694],\n",
      "        [ 0.4777, -1.7076, -1.2520],\n",
      "        [-0.6681,  0.0839, -0.7124],\n",
      "        [ 0.6443, -0.7696,  0.7994],\n",
      "        [ 1.7564, -0.2901, -0.2034]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# 查询Tensor size的方式\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7929, -0.3522, -1.3767],\n",
      "        [ 0.5334, -1.2761, -1.0927],\n",
      "        [ 0.1984,  0.6713, -0.5909],\n",
      "        [ 1.1114, -0.4335,  0.9478],\n",
      "        [ 2.0193,  0.0761,  0.5270]])\n",
      "tensor([[ 0.7929, -0.3522, -1.3767],\n",
      "        [ 0.5334, -1.2761, -1.0927],\n",
      "        [ 0.1984,  0.6713, -0.5909],\n",
      "        [ 1.1114, -0.4335,  0.9478],\n",
      "        [ 2.0193,  0.0761,  0.5270]])\n",
      "tensor([[ 0.7929, -0.3522, -1.3767],\n",
      "        [ 0.5334, -1.2761, -1.0927],\n",
      "        [ 0.1984,  0.6713, -0.5909],\n",
      "        [ 1.1114, -0.4335,  0.9478],\n",
      "        [ 2.0193,  0.0761,  0.5270]])\n"
     ]
    }
   ],
   "source": [
    "# torch 中的三种加法\n",
    "# 1.直接加\n",
    "print(x+y)\n",
    "# 2.torch.add\n",
    "print(torch.add(x, y))\n",
    "# 3.in-place add\n",
    "print(y.add_(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1806, 1.9142, 1.7044],\n",
      "        [1.7395, 0.8616, 1.4314],\n",
      "        [0.6051, 0.9916, 1.2903],\n",
      "        [1.1836, 1.6148, 1.3720],\n",
      "        [1.4465, 0.7107, 1.9083]])\n",
      "tensor([[1.1806, 1.9142, 1.7044],\n",
      "        [1.7395, 0.8616, 1.4314],\n",
      "        [0.6051, 0.9916, 1.2903],\n",
      "        [1.1836, 1.6148, 1.3720],\n",
      "        [1.4465, 0.7107, 1.9083]])\n"
     ]
    }
   ],
   "source": [
    "# torch_add 两种返回output的方法\n",
    "x = torch.rand(5,3)\n",
    "y = torch.rand(5,3)\n",
    "result = torch.add(x, y)\n",
    "print(result)\n",
    "\n",
    "result1 = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result1)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4974, 0.9947, 0.7792],\n",
      "        [0.9095, 0.6416, 0.4938],\n",
      "        [0.2854, 0.2684, 0.8541],\n",
      "        [0.8873, 0.9396, 0.4515],\n",
      "        [0.9033, 0.1339, 0.9775]])\n",
      "tensor([[0.4974, 0.9095, 0.2854, 0.8873, 0.9033],\n",
      "        [0.9947, 0.6416, 0.2684, 0.9396, 0.1339],\n",
      "        [0.7792, 0.4938, 0.8541, 0.4515, 0.9775]])\n"
     ]
    }
   ],
   "source": [
    "# in-place transpose Tensor.t_() 这个method里面不带argument，不会返回值\n",
    "print(x)\n",
    "x.t_()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# 以前用的是tf.reshape，现在是reshape(Tensor.view(shape))\n",
    "# x本身的尺寸没有被改变，所以需要把改变了尺寸的返回值赋给新的变量\n",
    "x = torch.rand(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03640854358673096\n",
      "[0.77645737 0.2608863  0.95201707 0.2121417  0.9053331  0.22455418\n",
      " 0.70432055 0.31426013 0.6277877  0.00821447 0.2924137  0.95873255\n",
      " 0.77784634 0.8357931  0.5650422  0.6265518 ]\n"
     ]
    }
   ],
   "source": [
    "# 如果Tensor只有一个element，还可以用Tensor.item()的方法把它转化为一个python scalar\n",
    "# 想要numpy array，可以用Tensor.numpy()\n",
    "x = torch.rand(1)\n",
    "print(x.item())\n",
    "print(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.4232, 5.2256],\n",
      "        [5.6462, 5.5090]])\n",
      "tensor([[5.4232, 5.2256],\n",
      "        [5.6462, 5.5090]])\n",
      "tensor([[5.4232, 5.2256],\n",
      "        [5.6462, 5.5090]])\n",
      "[[5.4231896 5.225643 ]\n",
      " [5.6461763 5.509046 ]]\n",
      "[[6.4231896 6.225643 ]\n",
      " [6.6461763 6.509046 ]]\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 在pytorch中加减乘除可以自动broadcast\n",
    "# 而且将设置一个变量为Tensor对应的numpy array后，将自动追踪改Tensor的变化情况，因为numpy array 和Tensor都共用一个内存位置\n",
    "x = torch.rand(2,2)\n",
    "y = x.numpy()\n",
    "print(x+5)\n",
    "print(torch.add(x, 5))\n",
    "print(x.add_(5))\n",
    "print(y)\n",
    "x += 1\n",
    "print(y)\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# numpy array 转化为Tensor的方法\n",
    "# 与numpy array 会自动追踪Tensor一样， Tensor也会自动追踪 numpy array的数值\n",
    "import numpy as np\n",
    "# numpy 和 TF 一样，shape都必须添加parentheses作为形状\n",
    "a = np.ones((5,3)) \n",
    "b = torch.from_numpy(a)\n",
    "print(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) /job:localhost/replica:0/task:0/device:CPU:0\n",
      "[2 3 4 5]\n",
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 在TF2中，虽然Tensor也可以转化为numpy array，但是因为他们不共享内存，所以即使都在CPU上运行，互相没有影响\n",
    "import tensorflow as tf\n",
    "a = tf.constant([1,2,3,4])\n",
    "print(a,a.device)\n",
    "b = a.numpy()\n",
    "b += 1\n",
    "print(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "tensor([[7.4232, 7.2256],\n",
      "        [7.6462, 7.5090]], device='cuda:0')\n",
      "tensor([[7.4232, 7.2256],\n",
      "        [7.6462, 7.5090]]) torch.float64\n",
      "cuda:0\n",
      "tensor([[7.4232, 7.2256],\n",
      "        [7.6462, 7.5090]])\n",
      "tensor([[6.4232, 6.2256],\n",
      "        [6.6462, 6.5090]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    # 在指定device上创建Tensor\n",
    "    y = torch.ones_like(x, device=device)\n",
    "#     将现有的Tensor移动到指定设备， 可以同时改变他们的dtype\n",
    "    print(x.device)\n",
    "    x = x.to(device)\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to('cpu'), torch.double)\n",
    "#     利用tensor.device可以查询他们现在位于哪个devide，注意，这不是一个method，所以不可以call， 这只是一个property\n",
    "    print(z.device)\n",
    "    # x现在作为存储在cuda上的Tensor，不可以用Tensor.numpy()的方法转化为numpy array，必须要先将用Tensor.cpu()的方法，\n",
    "#     将它保存在内存上，再用Tensor.numpy()的方法将它转化为numpy array，所以自然没有numpy和PyTorch Tensor那种自动追踪\n",
    "    tensor_cpu = x.cpu()\n",
    "    print(tensor_cpu + 1)\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
